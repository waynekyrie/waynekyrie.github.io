---
layout: post
title:  "Automating Robot Failure Recovery Using Vision-Language Models With Optimized Prompts"
date:   2025-01-17 18:08:39 +00:00
image: /images/failure_detection.png
categories: research
author: "Ruixuan Liu"
authors: "Hongyi Chen, Yunchao Yao, <strong>Ruixuan Liu</strong>, Changliu Liu, Jeffrey Ichnowski"
location: "Pittsburgh, PA"
sponsor: "CMU MFI"
arxiv: https://arxiv.org/abs/2409.03966
venue: "American Control Conference (ACC)"
code: https://github.com/hychen-naza/Robot_ErrorRecovery_VLM.git
---
This paper investigates how optimizing visual and text prompts can enhance the spatial reasoning of VLMs, enabling them to function effectively as black-box controllers for both motion-level position correction and task-level recovery from unknown failures. 
Specifically, the optimizations include identifying key visual elements in visual prompts, highlighting these elements in text prompts for querying, and decomposing the reasoning process for failure detection and control generation. 