---
layout: post
title:  "GUARD: A Safe Reinforcement Learning Benchmark"
date:   2024-03-31 18:08:39 +00:00
image: /images/guard.png
categories: research
author: "Ruixuan Liu"
authors: "Weiye Zhao, Rui Chen, Yifan Sun, <strong>Ruixuan Liu</strong>, Tianhao Wei, Changliu Liu"
location: "Pittsburgh, PA"
sponsor: "NSF"
venue: "Transactions on Machine Learning Research (TMLR)"
code: https://github.com/intelligent-control-lab/guard
arxiv: https://arxiv.org/abs/2305.13681
---
This paper introduces GUARD, a Generalized Unified SAfe Reinforcement Learning Development Benchmark. 
GUARD has several advantages compared to existing benchmarks. 
First, GUARD is a generalized benchmark with a wide variety of RL agents, tasks, and safety constraint specifications. 
Second, GUARD comprehensively covers state-of-the-art safe RL algorithms with self-contained implementations. 
Third, GUARD is highly customizable in tasks and algorithms.